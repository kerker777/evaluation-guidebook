# 基礎概念

## 什麼是評判模型評估？
評判模型簡單來說就是**用來評估其他神經網路輸出的神經網路**。在大多數情況下，它們用於評估文字生成的結果。

評判模型的範圍很廣，從小型專用分類器（例如「垃圾郵件過濾器」，但用於評估毒性內容）到大型語言模型（LLM），可以是大型通用模型或小型專用模型。在後者的情況下，當使用 LLM 作為評判者時，你需要提供一個提示詞來說明如何為模型評分（例如：`請以 0 到 5 分評估流暢度，0 分代表完全無法理解，...`）。

模型作為評判者可以針對複雜且細緻的特性進行文字評分。
例如，預測結果與參考答案的完全匹配可以讓你測試模型是否預測出正確的事實或數字，但要評估更開放式的實證能力（如流暢度、詩歌品質或對輸入的忠實度）則需要更複雜的評估器。

這就是模型作為評判者發揮作用的地方。

它們主要用於 3 種任務：
- *為模型生成結果評分*：在提供的評分尺度上評估文字的某項特性（流暢度、毒性、連貫性、說服力等）。
- *成對評分*：比較一對模型輸出，根據給定特性挑選出最佳的文字
- *計算相似度*：計算模型輸出與參考答案之間的相似度

*註：在本文中，我將主要關注 LLM + 提示詞的方法，但你也應該了解分類器評判者的運作方式，因為我認為它在許多使用情境中相當穩健且適用。此外，最近還推出了很有前景的獎勵模型作為評判者的方法（在[這份技術報告](https://research.nvidia.com/publication/2024-06_nemotron-4-340b)中介紹，我們也有一個簡短的說明頁面[在這裡](https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/what-about-reward-models.md)）*

## 使用 LLM 作為評判者的優缺點
LLM 評判者被使用的原因包括：
- **客觀性**（相較於人類）：它們以客觀且可重現的方式自動化實證判斷
- **規模化與可重現性**：相比人類標註者更具擴展性，可以在大量資料上重現評分
- **成本**：它們的建置成本較低，因為不需要訓練新模型，只需仰賴良好的提示詞和現有的高品質 LLM。它們也比雇用真正的人類標註者便宜
- **與人類判斷的一致性**：它們在某種程度上與人類判斷相關

然而，這些優點也都有其缺點：
- LLM 評判者看似客觀，但它們有許多**隱藏的偏誤**，這些偏誤可能比人類的偏誤更難察覺，因為我們不會像對待人類那樣積極尋找這些偏誤（參見 [model-as-a-judge/Tips and tricks]）。此外，有許多方法可以透過以特定且統計上穩健的方式設計調查問題來減少人類偏誤（這在社會學領域已經研究了大約一個世紀），而 LLM 提示詞工程還沒有那麼穩健。使用 LLM 來評估 LLM 被比喻為創造一種同溫層效應，微妙地強化了偏誤。
- 它們確實具有擴展性，但會產生大量需要被檢查以確保品質的資料（例如，你可以透過要求 LLM 評判者生成思考軌跡或對其資料進行推理來提高其品質，這又會產生更多需要分析的人工資料）
- 它們的建置成本確實較低，但雇用真正的專家級人類標註者可能會為你的特定使用情境帶來質量更好的結果

## 如何開始？
- 如果你想嘗試看看，我建議先閱讀 Aymeric Roucher 撰寫的這份[非常好的指南](https://huggingface.co/learn/cookbook/en/llm_judge)（⭐），了解如何設定你的第一個 LLM 評判者！
你也可以試試 [distilabel](https://distilabel.argilla.io/latest/) 函式庫，它可以讓你生成合成資料並使用 LLM 進行更新。他們有一個不錯的[教學](https://distilabel.argilla.io/latest/sections/pipeline_samples/papers/ultrafeedback/)，應用了 [Ultrafeedback 論文](https://arxiv.org/abs/2310.01377)的方法，以及一個[基準測試教學](https://distilabel.argilla.io/latest/sections/pipeline_samples/examples/benchmarking_with_distilabel/)，實作了 Arena Hard 基準測試。
